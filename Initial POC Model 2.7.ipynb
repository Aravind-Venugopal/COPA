{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Install packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "//anaconda3/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COPA_forum_threads.csv',\n",
       " 'Parsed Magazine.csv',\n",
       " 'wiki_formal_total_clean.csv',\n",
       " 'COPA_Blogs.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for filename in glob.glob('*.csv'):\n",
    "    data.append(filename)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum = pd.read_csv(data[0])\n",
    "data = forum.FormattedBody.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model for topic classification based on the dataset we have \n",
    "# (It may cause some problems because the model will be applied to the dataset later to give each content a topic.)\n",
    "# (The problem can be solved when we get the entire dataset since we can take part of the contents as corpus.)\n",
    "\n",
    "# Get some stop words\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.035*\"copa\" + 0.031*\"member\" + 0.028*\"event\" + 0.024*\"email\" + '\n",
      "  '0.014*\"register\"'),\n",
      " (1,\n",
      "  '0.045*\"hour\" + 0.040*\"engine\" + 0.030*\"annual\" + 0.028*\"oil\" + '\n",
      "  '0.026*\"replace\"'),\n",
      " (2,\n",
      "  '0.049*\"system\" + 0.036*\"traffic\" + 0.036*\"avionic\" + 0.035*\"display\" + '\n",
      "  '0.033*\"upgrade\"'),\n",
      " (3,\n",
      "  '0.042*\"fly\" + 0.027*\"flight\" + 0.020*\"trip\" + 0.018*\"weather\" + '\n",
      "  '0.017*\"plan\"'),\n",
      " (4,\n",
      "  '0.036*\"update\" + 0.018*\"datum\" + 0.017*\"use\" + 0.017*\"page\" + 0.015*\"card\"'),\n",
      " (5,\n",
      "  '0.096*\"pilot\" + 0.050*\"flight\" + 0.043*\"training\" + 0.027*\"aircraft\" + '\n",
      "  '0.019*\"cirrus\"'),\n",
      " (6,\n",
      "  '0.219*\"com\" + 0.069*\"video\" + 0.043*\"watch\" + 0.043*\"article\" + '\n",
      "  '0.042*\"http_www\"'),\n",
      " (7, '0.028*\"get\" + 0.026*\"go\" + 0.021*\"plane\" + 0.019*\"say\" + 0.016*\"think\"'),\n",
      " (8,\n",
      "  '0.112*\"post\" + 0.043*\"thread\" + 0.039*\"find\" + 0.033*\"forum\" + 0.029*\"see\"'),\n",
      " (9,\n",
      "  '0.044*\"would\" + 0.031*\"thank\" + 0.030*\"look\" + 0.025*\"plane\" + 0.022*\"buy\"'),\n",
      " (10,\n",
      "  '0.035*\"approach\" + 0.020*\"fly\" + 0.018*\"runway\" + 0.015*\"land\" + '\n",
      "  '0.013*\"turn\"'),\n",
      " (11,\n",
      "  '0.017*\"may\" + 0.016*\"would\" + 0.015*\"issue\" + 0.008*\"require\" + '\n",
      "  '0.008*\"make\"'),\n",
      " (12,\n",
      "  '0.021*\"issue\" + 0.020*\"problem\" + 0.020*\"flight\" + 0.016*\"go\" + '\n",
      "  '0.014*\"start\"'),\n",
      " (13,\n",
      "  '0.067*\"aircraft\" + 0.034*\"new\" + 0.033*\"cirrus\" + 0.029*\"ad\" + '\n",
      "  '0.018*\"sale\"'),\n",
      " (14,\n",
      "  '0.028*\"battery\" + 0.028*\"use\" + 0.019*\"power\" + 0.018*\"seat\" + '\n",
      "  '0.017*\"ship\"'),\n",
      " (15,\n",
      "  '0.054*\"engine\" + 0.021*\"power\" + 0.021*\"high\" + 0.019*\"run\" + 0.017*\"fuel\"'),\n",
      " (16,\n",
      "  '0.025*\"jet\" + 0.020*\"year\" + 0.020*\"say\" + 0.017*\"company\" + '\n",
      "  '0.015*\"business\"'),\n",
      " (17,\n",
      "  '0.038*\"wing\" + 0.024*\"side\" + 0.022*\"right\" + 0.020*\"leave\" + '\n",
      "  '0.018*\"cover\"'),\n",
      " (18,\n",
      "  '0.028*\"fly\" + 0.023*\"year\" + 0.018*\"time\" + 0.013*\"great\" + 0.012*\"make\"'),\n",
      " (19,\n",
      "  '0.052*\"black\" + 0.028*\"white\" + 0.026*\"glass\" + 0.023*\"draw\" + '\n",
      "  '0.023*\"interior\"')]\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           passes=10)\n",
    "\n",
    "pprint(lda_model.print_topics(num_words = 5))\n",
    "# Get 20 related topics\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_csv(data[2])\n",
    "wiki = wiki[['Date', 'Title', 'Content', 'Author','Like']]\n",
    "wiki['Author'] = [a.strip() for a in wiki['Author']]\n",
    "wiki['Comment'] = 0\n",
    "wiki['Resource'] = 'Wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "magazine = pd.read_csv(data[1])\n",
    "magazine_date_list = list(magazine['Magazine'].unique())\n",
    "# Get the month of magazine from its name\n",
    "# Since the the COPA magazines are released monthly, so it only has year and month\n",
    "# in its date column. In this case we just assume all magazines were released on the \n",
    "# first day of that month.\n",
    "magazine_date_dict = {magazine_date_list[0]: '2015-01-01', magazine_date_list[1]: '2019-01-01',\n",
    "                      magazine_date_list[2]: '2015-07-01', magazine_date_list[3]: '2019-04-01',\n",
    "                      magazine_date_list[4]: '2019-06-01', magazine_date_list[5]: '2018-01-01',\n",
    "                      magazine_date_list[6]: '2017-09-01', magazine_date_list[7]: '2016-09-01',\n",
    "                      magazine_date_list[8]: '2017-11-01', magazine_date_list[9]: '2015-05-01',\n",
    "                      magazine_date_list[10]: '2015-09-01', magazine_date_list[11]: '2006-09-01', \n",
    "                      magazine_date_list[12]: '2018-06-01', magazine_date_list[13]: '2019-07-01',\n",
    "                      magazine_date_list[14]: '2017-04-01', magazine_date_list[15]: '2016-04-01',\n",
    "                      magazine_date_list[16]: '2018-11-01', magazine_date_list[17]: '2015-09-01',\n",
    "                      magazine_date_list[18]: '2019-03-01', magazine_date_list[19]: '2006-11-01',\n",
    "                      magazine_date_list[20]: '2016-01-01', magazine_date_list[21]: '2019-05-01',\n",
    "                      magazine_date_list[22]: '2016-03-01', magazine_date_list[23]: '2016-05-01',\n",
    "                      magazine_date_list[24]: '2006-07-01', magazine_date_list[25]: '2017-06-01',\n",
    "                      magazine_date_list[26]: '2018-07-01', magazine_date_list[27]: '2018-09-01',\n",
    "                      magazine_date_list[28]: '2017-01-01', magazine_date_list[29]: '2012-11-01'}\n",
    "magazine['Magazine'] = magazine['Magazine'].map(magazine_date_dict)\n",
    "magazine.columns = ['Date', 'Title', 'Content', 'Author']\n",
    "magazine['Like'] = 0\n",
    "magazine['Comment'] = 0\n",
    "magazine['Resource'] = 'Magazine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog = pd.read_csv(data[3], encoding = 'unicode_escape')\n",
    "blog = blog[['Date', 'Title', 'Body', 'Author', 'Like','Comment']]\n",
    "blog.columns = ['Date', 'Title', 'Content', 'Author', 'Like','Comment']\n",
    "blog['Date'] = [d.split(' ')[0].split('/')[2] + '-' + d.split(' ')[0].split('/')[0] for d in blog['Date']]\n",
    "blog['Date'] = blog['Date'].map(lambda x: x + '-01')\n",
    "blog['Resource'] = 'Blog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdList = [magazine, wiki, blog]\n",
    "# Combine three datasets together\n",
    "df = pd.concat(pdList)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking the source, blog is the most important source so have 3\n",
    "raw_data = {'Resource': ['Wiki','Blog','Magazine'], 'SourceScore': [1, 2, 3]}\n",
    "Source_tb = pd.DataFrame(raw_data, columns = ['Resource', 'SourceScore'])\n",
    "#add source score to the main table\n",
    "df = pd.merge(df, Source_tb, left_on = 'Resource', right_on = 'Resource')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generate Recency Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  Calculate_RecencyScore(date):\n",
    "    '''\n",
    "    Recency Rate = log( 1 + 1/(days between the post date and current date + 1))\n",
    "    '''\n",
    "    date_datetime = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    rececncy_rate = math.log10(1/(((datetime.date(datetime.now()))-date_datetime).days+1)+1)\n",
    "    return rececncy_rate\n",
    "    \n",
    "\n",
    "df['RecencyRate'] = df['Date'].map(lambda y: Calculate_RecencyScore(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generate Author Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_AuthorScore(author):\n",
    "    '''\n",
    "    AuthorScore = Number of posts of specified content source * pre-determined weight\n",
    "    '''\n",
    "    author_score = df[df['Author'] == author]['SourceScore'].sum()\n",
    "    return author_score\n",
    "\n",
    "author_list = list(df['Author'].unique())\n",
    "df['AuthorScore'] = df['Author'].map(lambda x: Calculate_AuthorScore(x), author_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(col):\n",
    "    nomolized_col = (df[col] - df[col].mean()) / df.loc[:, col].std()\n",
    "    return nomolized_col\n",
    "\n",
    "df['RecencyRate'] = Normalization('RecencyRate')\n",
    "df['AuthorScore'] = Normalization('AuthorScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Author</th>\n",
       "      <th>Like</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Resource</th>\n",
       "      <th>SourceScore</th>\n",
       "      <th>RecencyRate</th>\n",
       "      <th>AuthorScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>President's Column</td>\n",
       "      <td>JANUARY FEBRUARY 20154CIRRUS PILOTAs this is b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.465959</td>\n",
       "      <td>-1.209951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>COPA News</td>\n",
       "      <td>JANUARY FEBRUARY 20156CIRRUS PILOTWith this is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.465959</td>\n",
       "      <td>-1.209951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Regional News</td>\n",
       "      <td>JANUARY FEBRUARY 201512CIRRUS PILOTby GIL WILL...</td>\n",
       "      <td>GIL WILLIAMSON</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.465959</td>\n",
       "      <td>0.211050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Cirrus Perspective</td>\n",
       "      <td>JANUARY FEBRUARY 201518CIRRUS PILOTIts hard to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.465959</td>\n",
       "      <td>-1.209951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Member Spotlight</td>\n",
       "      <td>JANUARY FEBRUARY 201522CIRRUS PILOTCirrus Pilo...</td>\n",
       "      <td>KIM BLONIGEN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Magazine</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.465959</td>\n",
       "      <td>0.211050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date               Title  \\\n",
       "0  2015-01-01  President's Column   \n",
       "1  2015-01-01           COPA News   \n",
       "2  2015-01-01       Regional News   \n",
       "3  2015-01-01  Cirrus Perspective   \n",
       "4  2015-01-01    Member Spotlight   \n",
       "\n",
       "                                             Content          Author  Like  \\\n",
       "0  JANUARY FEBRUARY 20154CIRRUS PILOTAs this is b...             NaN     0   \n",
       "1  JANUARY FEBRUARY 20156CIRRUS PILOTWith this is...             NaN     0   \n",
       "2  JANUARY FEBRUARY 201512CIRRUS PILOTby GIL WILL...  GIL WILLIAMSON     0   \n",
       "3  JANUARY FEBRUARY 201518CIRRUS PILOTIts hard to...             NaN     0   \n",
       "4  JANUARY FEBRUARY 201522CIRRUS PILOTCirrus Pilo...    KIM BLONIGEN     0   \n",
       "\n",
       "   Comment  Resource  SourceScore  RecencyRate  AuthorScore  \n",
       "0        0  Magazine            3    -0.465959    -1.209951  \n",
       "1        0  Magazine            3    -0.465959    -1.209951  \n",
       "2        0  Magazine            3    -0.465959     0.211050  \n",
       "3        0  Magazine            3    -0.465959    -1.209951  \n",
       "4        0  Magazine            3    -0.465959     0.211050  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

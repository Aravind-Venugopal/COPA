{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreContentScore = pd.read_csv(\"PreContentScore.csv\", engine='python')\n",
    "\n",
    "queries_df = pd.read_csv(\"SearchApiResults.csv\")\n",
    "queries_df = queries_df[['Query', 'url', 'ContentId', 'fancy_title']]\n",
    "queries_df = queries_df[queries_df['ContentId'].isna() != True]\n",
    "\n",
    "PreContentScore_clean = PreContentScore[PreContentScore.columns[3:]]\n",
    "PreContentScore_clean = PreContentScore_clean[PreContentScore_clean['ContentId'].isna() != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>url</th>\n",
       "      <th>ContentId</th>\n",
       "      <th>fancy_title</th>\n",
       "      <th>Date</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Title</th>\n",
       "      <th>FormattedBody</th>\n",
       "      <th>TotalViews</th>\n",
       "      <th>Source</th>\n",
       "      <th>SourceScore</th>\n",
       "      <th>RecencyRate</th>\n",
       "      <th>AuthorScore</th>\n",
       "      <th>TopicID</th>\n",
       "      <th>PreContentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/41040/5</td>\n",
       "      <td>6D601E0C-14D7-41DB-BAEF-3A6333537AB8</td>\n",
       "      <td>Cirrus SR22 Brake problems</td>\n",
       "      <td>2012-11-21</td>\n",
       "      <td>3695.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[quote user=\"David Martin\"]\\r\\nRobert that's w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>19536.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/65942/2</td>\n",
       "      <td>ADCD2721-0351-4DD7-8B07-AE423D3420F0</td>\n",
       "      <td>cirrus sr22 brake wear</td>\n",
       "      <td>2012-12-11</td>\n",
       "      <td>10652.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>19902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/25175/7</td>\n",
       "      <td>2A423C4C-B3E0-4C9C-95D1-A0A86ACE1465</td>\n",
       "      <td>Overheated, Failed Brakes</td>\n",
       "      <td>2005-04-20</td>\n",
       "      <td>3156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, the other guy had plenty of time to go ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/68466/1</td>\n",
       "      <td>AB750CAD-7103-48DC-BB4A-8B82B792B33E</td>\n",
       "      <td>Brake fire</td>\n",
       "      <td>2013-06-14</td>\n",
       "      <td>14208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Got a fresh annual.  On taxi, brakes clamped n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/26578/1</td>\n",
       "      <td>97F47B9B-F055-4F1D-9C56-8B5FF2A3D32C</td>\n",
       "      <td>Brake Failure and Fire</td>\n",
       "      <td>2005-08-12</td>\n",
       "      <td>4281.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Today, we had the right landing gear in our ai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>340.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Query                                       url  \\\n",
       "0  brakes during taxi  https://forum.cirruspilots.org/t/41040/5   \n",
       "1  brakes during taxi  https://forum.cirruspilots.org/t/65942/2   \n",
       "2  brakes during taxi  https://forum.cirruspilots.org/t/25175/7   \n",
       "3  brakes during taxi  https://forum.cirruspilots.org/t/68466/1   \n",
       "4  brakes during taxi  https://forum.cirruspilots.org/t/26578/1   \n",
       "\n",
       "                              ContentId                 fancy_title  \\\n",
       "0  6D601E0C-14D7-41DB-BAEF-3A6333537AB8  Cirrus SR22 Brake problems   \n",
       "1  ADCD2721-0351-4DD7-8B07-AE423D3420F0      cirrus sr22 brake wear   \n",
       "2  2A423C4C-B3E0-4C9C-95D1-A0A86ACE1465   Overheated, Failed Brakes   \n",
       "3  AB750CAD-7103-48DC-BB4A-8B82B792B33E                  Brake fire   \n",
       "4  97F47B9B-F055-4F1D-9C56-8B5FF2A3D32C      Brake Failure and Fire   \n",
       "\n",
       "         Date   UserID Title  \\\n",
       "0  2012-11-21   3695.0   NaN   \n",
       "1  2012-12-11  10652.0   NaN   \n",
       "2  2005-04-20   3156.0   NaN   \n",
       "3  2013-06-14  14208.0   NaN   \n",
       "4  2005-08-12   4281.0   NaN   \n",
       "\n",
       "                                       FormattedBody  TotalViews Source  \\\n",
       "0  [quote user=\"David Martin\"]\\r\\nRobert that's w...         NaN  Forum   \n",
       "1                                               [8)]         NaN  Forum   \n",
       "2  Yes, the other guy had plenty of time to go ar...         NaN  Forum   \n",
       "3  Got a fresh annual.  On taxi, brakes clamped n...         NaN  Forum   \n",
       "4  Today, we had the right landing gear in our ai...         NaN  Forum   \n",
       "\n",
       "   SourceScore  RecencyRate  AuthorScore  TopicID  PreContentScore  \n",
       "0          2.0     0.000161      19536.0      9.0            0.035  \n",
       "1          2.0     0.000162      19902.0      0.0            0.000  \n",
       "2          2.0     0.000079       2300.0      1.0            0.000  \n",
       "3          2.0     0.000174         14.0      6.0            0.000  \n",
       "4          2.0     0.000081        340.0      6.0            0.000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_query_df = pd.merge(queries_df, PreContentScore_clean, on = 'ContentId')\n",
    "all_query_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input LDA model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "filename = 'lda_model.pickle'\n",
    "infile = open(filename,'rb')\n",
    "lda_model = pickle.load(infile)\n",
    "\n",
    "filename = 'id2word.pickle'\n",
    "infile = open(filename,'rb')\n",
    "id2word = pickle.load(infile)\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Re-rank search results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_match(search_query):\n",
    "    '''\n",
    "    Extract the topic of searching query by LDA model trained by forum posts\n",
    "    '''\n",
    "    texts1 = [[word for word in doc.lower().split() if word not in stop_words] for doc in [search_query]]\n",
    "    corpus1 = [id2word.doc2bow(t) for t in texts1]\n",
    "    result = lda_model.get_document_topics(corpus1)\n",
    "    LDA_topic = max(result[0], key=lambda x: x[1])\n",
    "    \n",
    "    return LDA_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_from_query(query):\n",
    "    '''\n",
    "    Extract keywords from query\n",
    "    '''\n",
    "    query_word = [word for word in query.split() if word not in stop_words]\n",
    "    \n",
    "    return query_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_match(post):\n",
    "    '''\n",
    "    Count the number of word matching between search query and posts\n",
    "    '''\n",
    "    summa = 0\n",
    "    for word in list(set(query_word)):\n",
    "        ratio = post.count(word) / len(post)\n",
    "        summa += ratio\n",
    "    \n",
    "    return summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_match(post):\n",
    "    '''\n",
    "    Count the number of word matching between search query and posts\n",
    "    '''\n",
    "    summa = 0\n",
    "    for word in list(set(query_word)):\n",
    "        summa += post.count(word)\n",
    "    \n",
    "    return summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(col, df):\n",
    "    '''\n",
    "    Normalize data in three attributes\n",
    "    '''\n",
    "    nomolized_col = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    \n",
    "    return nomolized_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights(weights, df):\n",
    "    '''\n",
    "    Assign different sets of weights to three attributes\n",
    "    '''\n",
    "    df_copy = df.copy()\n",
    "    df_copy['TotalScore'] = df['RecencyRate'] * weights[0] + df['AuthorScore'] * weights[1] + df['TotalContentScore'] * weights[2]\n",
    "    df_copy.sort_values(\"TotalScore\", inplace = True, ascending=False)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_index(df):\n",
    "    '''\n",
    "    Reset the index of a dataframe\n",
    "    '''\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1 = ''\n",
    "comb2 = ''\n",
    "comb3 = ''\n",
    "\n",
    "query_list = list(all_query_df['Query'].unique())\n",
    "for query in query_list:\n",
    "    # Take the subset of rearch results from the query\n",
    "    sub_dataset = all_query_df[all_query_df['Query'] == query]\n",
    "    sub_dataset['ContentScore'] = sub_dataset['PreContentScore']\n",
    "    # Assign topic id to search query\n",
    "    topic_id = topic_match(query)\n",
    "    # Calculate content score\n",
    "    sub_dataset.loc[sub_dataset['TopicID'] == topic_id, 'ContentScore'] = sub_dataset.loc[sub_dataset['TopicID'] == topic_id, 'PreContentScore'] * 5\n",
    "    \n",
    "    query_word = keyword_from_query(query)\n",
    "    sub_dataset['Match'] = sub_dataset['FormattedBody'].apply(ratio_match)\n",
    "    \n",
    "    # Normalize data\n",
    "    for col in ['RecencyRate', 'AuthorScore', 'ContentScore', 'Match']:\n",
    "        sub_dataset.loc[:,col] = Normalization(col, sub_dataset)\n",
    "    \n",
    "    sub_dataset['TotalContentScore'] = 0.3 * sub_dataset['ContentScore'] + 0.7 * sub_dataset['Match']\n",
    "    \n",
    "    # Apply three sets of weights that add up to the total score\n",
    "    temp1 = assign_weights([1/2, 2/9, 1/3], sub_dataset)\n",
    "    temp2 = assign_weights([1/5, 3/10, 1/2], sub_dataset)\n",
    "    temp3 = assign_weights([1/3, 1/3, 1/3], sub_dataset)\n",
    "    \n",
    "    if type(comb1) == str:\n",
    "        comb1 = temp1\n",
    "        comb2 = temp2\n",
    "        comb3 = temp3\n",
    "    else:\n",
    "        # Combine search results for all search queries\n",
    "        comb1 = pd.concat([comb1, temp1])\n",
    "        comb2 = pd.concat([comb2, temp2])\n",
    "        comb3 = pd.concat([comb3, temp3])\n",
    "\n",
    "for df in [comb1, comb2, comb3]:\n",
    "    reset_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('count_comb1.csv') # 1/2, 2/9, 1/3\n",
    "comb2[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('count_comb2.csv') # 1/5, 3/10, 1/2\n",
    "comb3[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('count_comb3.csv') # 1/3, 1/3, 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('ratio_comb1.csv') # 1/2, 2/9, 1/3\n",
    "comb2[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('ratio_comb2.csv') # 1/5, 3/10, 1/2\n",
    "comb3[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('ratio_comb3.csv') # 1/3, 1/3, 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreContentScore = pd.read_csv(\"PreContentScore.csv\", engine='python')\n",
    "\n",
    "queries_df = pd.read_csv(\"SearchApiResults.csv\")\n",
    "queries_df = queries_df[['Query', 'url', 'ContentId', 'fancy_title']]\n",
    "queries_df = queries_df[queries_df['ContentId'].isna() != True]\n",
    "\n",
    "PreContentScore_clean = PreContentScore[PreContentScore.columns[3:]]\n",
    "PreContentScore_clean = PreContentScore_clean[PreContentScore_clean['ContentId'].isna() != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>url</th>\n",
       "      <th>ContentId</th>\n",
       "      <th>fancy_title</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Title</th>\n",
       "      <th>FormattedBody</th>\n",
       "      <th>TotalViews</th>\n",
       "      <th>Source</th>\n",
       "      <th>SourceScore</th>\n",
       "      <th>RecencyRate</th>\n",
       "      <th>AuthorScore</th>\n",
       "      <th>TopicID</th>\n",
       "      <th>PreContentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/41040/5</td>\n",
       "      <td>6D601E0C-14D7-41DB-BAEF-3A6333537AB8</td>\n",
       "      <td>Cirrus SR22 Brake problems</td>\n",
       "      <td>3695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[quote user=\"David Martin\"]\\r\\nRobert that's w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>19536</td>\n",
       "      <td>9</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/65942/2</td>\n",
       "      <td>ADCD2721-0351-4DD7-8B07-AE423D3420F0</td>\n",
       "      <td>cirrus sr22 brake wear</td>\n",
       "      <td>10652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8)]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>19902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/25175/7</td>\n",
       "      <td>2A423C4C-B3E0-4C9C-95D1-A0A86ACE1465</td>\n",
       "      <td>Overheated, Failed Brakes</td>\n",
       "      <td>3156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, the other guy had plenty of time to go ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/68466/1</td>\n",
       "      <td>AB750CAD-7103-48DC-BB4A-8B82B792B33E</td>\n",
       "      <td>Brake fire</td>\n",
       "      <td>14208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Got a fresh annual.  On taxi, brakes clamped n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>brakes during taxi</td>\n",
       "      <td>https://forum.cirruspilots.org/t/26578/1</td>\n",
       "      <td>97F47B9B-F055-4F1D-9C56-8B5FF2A3D32C</td>\n",
       "      <td>Brake Failure and Fire</td>\n",
       "      <td>4281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Today, we had the right landing gear in our ai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forum</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>340</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Query                                       url  \\\n",
       "0  brakes during taxi  https://forum.cirruspilots.org/t/41040/5   \n",
       "1  brakes during taxi  https://forum.cirruspilots.org/t/65942/2   \n",
       "2  brakes during taxi  https://forum.cirruspilots.org/t/25175/7   \n",
       "3  brakes during taxi  https://forum.cirruspilots.org/t/68466/1   \n",
       "4  brakes during taxi  https://forum.cirruspilots.org/t/26578/1   \n",
       "\n",
       "                              ContentId                 fancy_title  UserID  \\\n",
       "0  6D601E0C-14D7-41DB-BAEF-3A6333537AB8  Cirrus SR22 Brake problems    3695   \n",
       "1  ADCD2721-0351-4DD7-8B07-AE423D3420F0      cirrus sr22 brake wear   10652   \n",
       "2  2A423C4C-B3E0-4C9C-95D1-A0A86ACE1465   Overheated, Failed Brakes    3156   \n",
       "3  AB750CAD-7103-48DC-BB4A-8B82B792B33E                  Brake fire   14208   \n",
       "4  97F47B9B-F055-4F1D-9C56-8B5FF2A3D32C      Brake Failure and Fire    4281   \n",
       "\n",
       "  Title                                      FormattedBody  TotalViews Source  \\\n",
       "0   NaN  [quote user=\"David Martin\"]\\r\\nRobert that's w...         NaN  Forum   \n",
       "1   NaN                                               [8)]         NaN  Forum   \n",
       "2   NaN  Yes, the other guy had plenty of time to go ar...         NaN  Forum   \n",
       "3   NaN  Got a fresh annual.  On taxi, brakes clamped n...         NaN  Forum   \n",
       "4   NaN  Today, we had the right landing gear in our ai...         NaN  Forum   \n",
       "\n",
       "   SourceScore  RecencyRate  AuthorScore  TopicID  PreContentScore  \n",
       "0            2     0.000163        19536        9            0.035  \n",
       "1            2     0.000164        19902        0            0.000  \n",
       "2            2     0.000080         2300        1            0.000  \n",
       "3            2     0.000176           14        6            0.000  \n",
       "4            2     0.000082          340        6            0.000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_query_df = pd.merge(queries_df, PreContentScore_clean, on = 'ContentId')\n",
    "all_query_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input LDA model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "filename = 'lda_model.pickle'\n",
    "infile = open(filename,'rb')\n",
    "lda_model = pickle.load(infile)\n",
    "\n",
    "filename = 'id2word.pickle'\n",
    "infile = open(filename,'rb')\n",
    "id2word = pickle.load(infile)\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Re-rank search results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_match(search_query):\n",
    "    '''\n",
    "    Extract the topic of searching query by LDA model trained by forum posts\n",
    "    '''\n",
    "    texts1 = [[word for word in doc.lower().split() if word not in stop_words] for doc in [search_query]]\n",
    "    corpus1 = [id2word.doc2bow(t) for t in texts1]\n",
    "    result = lda_model.get_document_topics(corpus1)\n",
    "    LDA_topic = max(result[0], key=lambda x: x[1])\n",
    "    \n",
    "    return LDA_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_from_query(query):\n",
    "    '''\n",
    "    Extract keywords from query\n",
    "    '''\n",
    "    query_word = [word for word in query.split() if word not in stop_words]\n",
    "    \n",
    "    return query_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_WordPairs(query_word, wordPairs):\n",
    "    '''\n",
    "    Return a list of pre-defined word pairs that are contained by the search query\n",
    "    '''\n",
    "    query_string = ' '.join(query_word)\n",
    "    matched_wordpair = list()\n",
    "    for wordpair in wordPairs:\n",
    "        if query_string.lower().count(wordpair) > 0:\n",
    "            matched_wordpair.append(wordpair)\n",
    "    return matched_wordpair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_wordpair_match(post):\n",
    "    '''\n",
    "    Count the ratio of word pair matching between search query and posts\n",
    "    '''\n",
    "    summa = 0\n",
    "    \n",
    "    matched_wordpairs = hit_WordPairs(query_word, wordPairs)\n",
    "    \n",
    "    if len(matched_wordpairs) != 0:\n",
    "        for matched_wordpair in matched_wordpairs:\n",
    "            ratio = post.lower().count(matched_wordpair) / len(post)\n",
    "            summa += ratio\n",
    "            \n",
    "    return summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_word_match(post):\n",
    "    '''\n",
    "    Count the ratio of word matching between search query and posts\n",
    "    '''\n",
    "    summa = 0\n",
    "    \n",
    "    for word in list(set(query_word)):\n",
    "        ratio = post.lower().count(word) / len(post)\n",
    "        summa += ratio\n",
    "    \n",
    "    return summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(col, df):\n",
    "    '''\n",
    "    Normalize data in three attributes\n",
    "    '''\n",
    "    nomolized_col = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    \n",
    "    return nomolized_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights(weights, df):\n",
    "    '''\n",
    "    Assign different sets of weights to three attributes\n",
    "    '''\n",
    "    df_copy = df.copy()\n",
    "    df_copy['TotalScore'] = df['RecencyRate'] * weights[0] + df['AuthorScore'] * weights[1] + df['TotalContentScore'] * weights[2]\n",
    "    df_copy.sort_values(\"TotalScore\", inplace = True, ascending=False)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_index(df):\n",
    "    '''\n",
    "    Reset the index of a dataframe\n",
    "    '''\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1 = ''\n",
    "comb2 = ''\n",
    "comb3 = ''\n",
    "\n",
    "query_list = list(all_query_df['Query'].unique())\n",
    "for query in query_list:\n",
    "    # Take the subset of search results from the query\n",
    "    sub_dataset = all_query_df[all_query_df['Query'] == query]\n",
    "    sub_dataset['ContentScore'] = sub_dataset['PreContentScore']\n",
    "    # Assign topic id to search query\n",
    "    topic_id = topic_match(query)\n",
    "    # Calculate content score\n",
    "    sub_dataset.loc[sub_dataset['TopicID'] == topic_id, 'ContentScore'] = sub_dataset.loc[sub_dataset['TopicID'] == topic_id, 'PreContentScore'] * 5\n",
    "    \n",
    "    query_word = keyword_from_query(query)\n",
    "    wordPairs = list(map(lambda x: x.lower(),list(pd.read_csv('WordPairs.csv')['Word Pairs'])))\n",
    "    sub_dataset['word_Match'] = sub_dataset['FormattedBody'].apply(ratio_word_match)\n",
    "    sub_dataset['wordpair_Match'] = sub_dataset['FormattedBody'].apply(ratio_wordpair_match)\n",
    "    \n",
    "    sub_dataset['Match'] = sub_dataset['word_Match'] + sub_dataset['wordpair_Match']\n",
    "    \n",
    "    # Normalize data\n",
    "    for col in ['RecencyRate', 'AuthorScore', 'ContentScore', 'Match']:\n",
    "        sub_dataset.loc[:,col] = Normalization(col, sub_dataset)\n",
    "    \n",
    "    sub_dataset['TotalContentScore'] = 0.3 * sub_dataset['ContentScore'] + 0.7 * sub_dataset['Match']\n",
    "    \n",
    "    # Apply three sets of weights that add up to the total score\n",
    "    temp1 = assign_weights([1/2, 2/9, 1/3], sub_dataset)\n",
    "    temp2 = assign_weights([1/5, 3/10, 1/2], sub_dataset)\n",
    "    temp3 = assign_weights([1/3, 1/3, 1/3], sub_dataset)\n",
    "    \n",
    "    if type(comb1) == str:\n",
    "        comb1 = temp1\n",
    "        comb2 = temp2\n",
    "        comb3 = temp3\n",
    "    else:\n",
    "        # Combine search results for all search queries\n",
    "        comb1 = pd.concat([comb1, temp1])\n",
    "        comb2 = pd.concat([comb2, temp2])\n",
    "        comb3 = pd.concat([comb3, temp3])\n",
    "\n",
    "for df in [comb1, comb2, comb3]:\n",
    "    reset_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('count_comb1.csv') # 1/2, 2/9, 1/3\n",
    "comb2[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('count_comb2.csv') # 1/5, 3/10, 1/2\n",
    "comb3[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('count_comb3.csv') # 1/3, 1/3, 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb1[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('ratio_comb1.csv') # 1/2, 2/9, 1/3\n",
    "comb2[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('ratio_comb2.csv') # 1/5, 3/10, 1/2\n",
    "comb3[['Query', 'url', 'ContentId', 'fancy_title']].to_csv('ratio_comb3.csv') # 1/3, 1/3, 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
